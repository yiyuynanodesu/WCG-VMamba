{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "83c4c5fc-9da0-45b3-9e92-ccafcfcb856f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'Identity' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 65\u001b[0m\n\u001b[1;32m     63\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(load_model_path))\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# print(model)\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m target_layers \u001b[38;5;241m=\u001b[39m [\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmamba_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mop\u001b[38;5;241m.\u001b[39mconv2d]\u001b[38;5;66;03m# VMmaba\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# target_layers = [model.mamba_model.layers[-1][-2][1].sk_conv]# WAVM\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m#cam = GradCAM(model=model, target_layers=target_layers, use_cuda=False)\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m GradCAM(model\u001b[38;5;241m=\u001b[39mmodel, target_layers\u001b[38;5;241m=\u001b[39mtarget_layers) \u001b[38;5;28;01mas\u001b[39;00m cam:\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# aug_smooth=True, eigen_smooth=True 使用图像增强是热力图变得更加平滑\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Identity' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from Models.OTEModel import Model\n",
    "from Config import config\n",
    "\n",
    "from pytorch_grad_cam import GradCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from torchvision.models import resnet50\n",
    "import torchvision\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "def myimshows(imgs, titles=False, fname=\"test.jpg\", size=6):\n",
    "    lens = len(imgs)\n",
    "    fig = plt.figure(figsize=(size * lens,size))\n",
    "    if titles == False:\n",
    "        titles=\"0123456789\"\n",
    "    for i in range(1, lens + 1):\n",
    "        cols = 100 + lens * 10 + i\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "        plt.subplot(cols)\n",
    "        if len(imgs[i - 1].shape) == 2:\n",
    "            plt.imshow(imgs[i - 1], cmap='Reds')\n",
    "        else:\n",
    "            plt.imshow(imgs[i - 1])\n",
    "        plt.title(titles[i - 1])\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.savefig(fname, bbox_inches='tight')\n",
    "    plt.show()\n",
    "def tensor2img(tensor,heatmap=False,shape=(224,224)):\n",
    "    np_arr=tensor.detach().numpy()#[0]\n",
    "    #对数据进行归一化\n",
    "    if np_arr.max()>1 or np_arr.min()<0:\n",
    "        np_arr=np_arr-np_arr.min()\n",
    "        np_arr=np_arr/np_arr.max()\n",
    "    #np_arr=(np_arr*255).astype(np.uint8)\n",
    "    if np_arr.shape[0]==1:\n",
    "        np_arr=np.concatenate([np_arr,np_arr,np_arr],axis=0)\n",
    "    np_arr=np_arr.transpose((1,2,0))\n",
    "    return np_arr\n",
    " \n",
    "# path=r\"../dataset/CornDataset/data/train/Blight/Corn_Blight (378).JPG\"\n",
    "# path=r\"../dataset/CornDataset/data/train/Common_Rust/Corn_Common_Rust (1262).JPG\"\n",
    "# path=r\"../dataset/CornDataset/data/train/Gray_Leaf_Spot/Corn_Gray_Spot (456).JPG\"\n",
    "# path=r\"../dataset/TomatoDataset/data/train/ Bacterial Spot/Bs257_jpg.rf.a1c837905341db0ab1c739da79c04c56.jpg\"\n",
    "# path=r\"../dataset/TomatoDataset/data/train/ Early Blight/Eb185_jpg.rf.c830431e7ecc0520de1c8a233ac5bd36.jpg\"\n",
    "# path=r\"../dataset/TomatoDataset/data/train/ Late Blight/Lb161_jpg.rf.978d22fb04d0af602c66fbf7d9943d96.jpg\"\n",
    "# path=r\"../dataset/TomatoDataset/data/train/ Leaf Mold/Lm226_jpg.rf.05e4fe9fbd6023ccdcb512300110d228.jpg\"\n",
    "path=r\"../dataset/TomatoDataset/data/train/ Mosaic Virus/0b5e2269-7b37-43ac-9a96-c62b9bba2383___PSU_CG-2243_90deg_JPG.rf.85e735ec568cea4c068282fcccc69894.jpg\"\n",
    "# path=r\"../dataset/TomatoDataset/data/train/ Septoria Leaf Spot/Slf103_jpg.rf.97d752f4cbe7cae49888b84e9491065a.jpg\"\n",
    "bin_data=torchvision.io.read_file(path)#加载二进制数据\n",
    "img=torchvision.io.decode_image(bin_data)/255#解码成CHW的图片\n",
    "img=img.unsqueeze(0)#变成BCHW的数据，B==1; squeeze\n",
    "input_tensor=torchvision.transforms.functional.resize(img,[224, 224])\n",
    " \n",
    "#对图像进行水平翻转，得到两个数据\n",
    "input_tensors=torch.cat([input_tensor, input_tensor.flip(dims=(3,))],axis=0)\n",
    "  \n",
    "model = Model(config).cuda()\n",
    "# load_model_path = './save_models/TomatoWAVM/pytorch_model.bin' # WAVM\n",
    "load_model_path = './save_models/CMAT/pytorch_model.bin' # VMamba\n",
    "model.load_state_dict(torch.load(load_model_path))\n",
    "print(model)\n",
    "# target_layers = [model.mamba_model.layers[-1][-2][1].op.conv2d]# VMmaba\n",
    "target_layers = [model.mamba_model.layers[-1][-2][1].op.conv2d]# VMmaba\n",
    "# target_layers = [model.mamba_model.layers[-1][-2][1].sk_conv]# WAVM\n",
    "#cam = GradCAM(model=model, target_layers=target_layers, use_cuda=False)\n",
    "with GradCAM(model=model, target_layers=target_layers) as cam:\n",
    "    # aug_smooth=True, eigen_smooth=True 使用图像增强是热力图变得更加平滑\n",
    "    grayscale_cams = cam(input_tensor=input_tensors)#targets=None 自动调用概率最大的类别显示\n",
    "    for grayscale_cam,tensor in zip(grayscale_cams,input_tensors):\n",
    "        #将热力图结果与原图进行融合\n",
    "        rgb_img=tensor2img(tensor)\n",
    "        visualization = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)\n",
    "        myimshows([rgb_img, grayscale_cam, visualization],[\"image\",\"cam\",\"image + cam\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35524ba3-de06-4d7f-b3c7-67f88fae6247",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
